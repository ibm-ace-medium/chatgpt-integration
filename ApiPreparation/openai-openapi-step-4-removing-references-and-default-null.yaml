openapi: 3.0.0
info:
  title: OpenAI API
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
  version: "2.0.0"
  termsOfService: https://openai.com/policies/terms-of-use
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE
servers:
  - url: https://api.openai.com/v1
tags:
  - name: Chat
    description: Given a list of messages comprising a conversation, the model will return a response.
paths:
  # Note: When adding an endpoint, make sure you also add it in the `groups` section, in the end of this file,
  # under the appropriate group
  /chat/completions:
    post:
      operationId: createChatCompletion
      tags:
        - Chat
      summary: Creates a model response for the given chat conversation.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateChatCompletionRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateChatCompletionResponse"

components:
  securitySchemes:
    ApiKeyAuth:
      type: http
      scheme: "bearer"

  schemas:
    Error:
      type: object
      properties:
        code:
          type: string
          nullable: true
        message:
          type: string
          nullable: false
        param:
          type: string
          nullable: true
        type:
          type: string
          nullable: false
      required:
        - type
        - message
        - param
        - code
    ErrorResponse:
      type: object
      properties:
        error:
          $ref: "#/components/schemas/Error"
      required:
        - error

    ChatCompletionRequestMessageContentPart:
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartImage"
      x-oaiExpandable: true

    ChatCompletionRequestMessageContentPartImage:
      type: object
      title: Image content part
      properties:
        type:
          type: string
          enum: ["image_url"]
          description: The type of the content part.
        image_url:
          type: object
          properties:
            url:
              type: string
              description: Either a URL of the image or the base64 encoded image data.
              format: uri
            detail:
              type: string
              description: Specifies the detail level of the image. Learn more in the [Vision guide](/docs/guides/vision/low-or-high-fidelity-image-understanding).
              enum: ["auto", "low", "high"]
              default: "auto"
          required:
            - url
      required:
        - type
        - image_url

    ChatCompletionRequestMessageContentPartText:
      type: object
      title: Text content part
      properties:
        type:
          type: string
          enum: ["text"]
          description: The type of the content part.
        text:
          type: string
          description: The text content.
      required:
        - type
        - text

    ChatCompletionRequestMessage:
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionRequestSystemMessage"
        - $ref: "#/components/schemas/ChatCompletionRequestUserMessage"
        - $ref: "#/components/schemas/ChatCompletionRequestAssistantMessage"
        - $ref: "#/components/schemas/ChatCompletionRequestToolMessage"
        - $ref: "#/components/schemas/ChatCompletionRequestFunctionMessage"
      x-oaiExpandable: true

    ChatCompletionRequestSystemMessage:
      type: object
      title: System message
      properties:
        content:
          description: The contents of the system message.
          type: string
        role:
          type: string
          enum: ["system"]
          description: The role of the messages author, in this case `system`.
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
      required:
        - content
        - role

    ChatCompletionRequestUserMessage:
      type: object
      title: User message
      properties:
        content:
          description: |
            The contents of the user message.
          oneOf:
            - type: string
              description: The text contents of the message.
              title: Text content
            - type: array
              description: An array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. Image input is only supported when using the `gpt-4-visual-preview` model.
              title: Array of content parts
              items:
                $ref: "#/components/schemas/ChatCompletionRequestMessageContentPart"
              minItems: 1
          x-oaiExpandable: true
        role:
          type: string
          enum: ["user"]
          description: The role of the messages author, in this case `user`.
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
      required:
        - content
        - role

    ChatCompletionRequestAssistantMessage:
      type: object
      title: Assistant message
      properties:
        content:
          nullable: true
          type: string
          description: |
            The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.
        role:
          type: string
          enum: ["assistant"]
          description: The role of the messages author, in this case `assistant`.
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
        tool_calls:
          $ref: "#/components/schemas/ChatCompletionMessageToolCalls"
        function_call:
          type: object
          deprecated: true
          description: "Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model."
          properties:
            arguments:
              type: string
              description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
            name:
              type: string
              description: The name of the function to call.
          required:
            - arguments
            - name
      required:
        - role

    ChatCompletionRequestToolMessage:
      type: object
      title: Tool message
      properties:
        role:
          type: string
          enum: ["tool"]
          description: The role of the messages author, in this case `tool`.
        content:
          type: string
          description: The contents of the tool message.
        tool_call_id:
          type: string
          description: Tool call that this message is responding to.
      required:
        - role
        - content
        - tool_call_id

    ChatCompletionRequestFunctionMessage:
      type: object
      title: Function message
      deprecated: true
      properties:
        role:
          type: string
          enum: ["function"]
          description: The role of the messages author, in this case `function`.
        content:
          nullable: true
          type: string
          description: The contents of the function message.
        name:
          type: string
          description: The name of the function to call.
      required:
        - role
        - content
        - name

    FunctionParameters:
      type: object
      description: "The parameters the functions accepts, described as a JSON Schema object. See the [guide](/docs/guides/text-generation/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format. \n\nOmitting `parameters` defines a function with an empty parameter list."
      additionalProperties: true

    ChatCompletionFunctions:
      type: object
      deprecated: true
      properties:
        description:
          type: string
          description: A description of what the function does, used by the model to choose when and how to call the function.
        name:
          type: string
          description: The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
        parameters:
          $ref: "#/components/schemas/FunctionParameters"
      required:
        - name

    ChatCompletionFunctionCallOption:
      type: object
      description: >
        Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.
      properties:
        name:
          type: string
          description: The name of the function to call.
      required:
        - name

    ChatCompletionTool:
      type: object
      properties:
        type:
          type: string
          enum: ["function"]
          description: The type of the tool. Currently, only `function` is supported.
        function:
          $ref: "#/components/schemas/FunctionObject"
      required:
        - type
        - function

    FunctionObject:
      type: object
      properties:
        description:
          type: string
          description: A description of what the function does, used by the model to choose when and how to call the function.
        name:
          type: string
          description: The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
        parameters:
          $ref: "#/components/schemas/FunctionParameters"
      required:
        - name

    ChatCompletionToolChoiceOption:
      description: |
        Controls which (if any) function is called by the model.
        `none` means the model will not call a function and instead generates a message.
        `auto` means the model can pick between generating a message or calling a function.
        Specifying a particular function via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that function.

        `none` is the default when no functions are present. `auto` is the default if functions are present.
      oneOf:
        - type: string
          description: >
            `none` means the model will not call a function and instead generates a message.
            `auto` means the model can pick between generating a message or calling a function.
          enum: [none, auto]
        - $ref: "#/components/schemas/ChatCompletionNamedToolChoice"
      x-oaiExpandable: true

    ChatCompletionNamedToolChoice:
      type: object
      description: Specifies a tool the model should use. Use to force the model to call a specific function.
      properties:
        type:
          type: string
          enum: ["function"]
          description: The type of the tool. Currently, only `function` is supported.
        function:
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
          required:
            - name
      required:
        - type
        - function

    ChatCompletionMessageToolCalls:
      type: array
      description: The tool calls generated by the model, such as function calls.
      items:
        $ref: "#/components/schemas/ChatCompletionMessageToolCall"

    ChatCompletionMessageToolCall:
      type: object
      properties:
        # TODO: index included when streaming
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          enum: ["function"]
          description: The type of the tool. Currently, only `function` is supported.
        function:
          type: object
          description: The function that the model called.
          properties:
            name:
              type: string
              description: The name of the function to call.
            arguments:
              type: string
              description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
          required:
            - name
            - arguments
      required:
        - id
        - type
        - function

    # Note, this isn't referenced anywhere, but is kept as a convenience to record all possible roles in one place.
    ChatCompletionRole:
      type: string
      description: The role of the author of a message
      enum:
        - system
        - user
        - assistant
        - tool
        - function

    ChatCompletionResponseMessage:
      type: object
      description: A chat completion message generated by the model.
      properties:
        content:
          type: string
          description: The contents of the message.
          nullable: true
        tool_calls:
          $ref: "#/components/schemas/ChatCompletionMessageToolCalls"
        role:
          type: string
          enum: ["assistant"]
          description: The role of the author of this message.
        function_call:
          type: object
          deprecated: true
          description: "Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model."
          properties:
            arguments:
              type: string
              description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
            name:
              type: string
              description: The name of the function to call.
          required:
            - name
            - arguments
      required:
        - role
        - content

    CreateChatCompletionRequest:
      type: object
      properties:
        messages:
          description: A list of messages comprising the conversation so far. [Example Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models).
          type: array
          minItems: 1
          items:
            $ref: "#/components/schemas/ChatCompletionRequestMessage"
        model:
          description: ID of the model to use. See the [model endpoint compatibility](/docs/models/model-endpoint-compatibility) table for details on which models work with the Chat API.
          example: "gpt-3.5-turbo"
          anyOf:
            - type: string
            - type: string
              enum:
                [
                  "gpt-4-0125-preview",
                  "gpt-4-turbo-preview",
                  "gpt-4-1106-preview",
                  "gpt-4-vision-preview",
                  "gpt-4",
                  "gpt-4-0314",
                  "gpt-4-0613",
                  "gpt-4-32k",
                  "gpt-4-32k-0314",
                  "gpt-4-32k-0613",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-16k",
                  "gpt-3.5-turbo-0301",
                  "gpt-3.5-turbo-0613",
                  "gpt-3.5-turbo-1106",
                  "gpt-3.5-turbo-0125",
                  "gpt-3.5-turbo-16k-0613",
                ]
          x-oaiTypeLabel: string
        frequency_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
        logit_bias:
          type: object
          x-oaiTypeLabel: map
          nullable: true
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
        logprobs:
          description: Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`. This option is currently not available on the `gpt-4-vision-preview` model.
          type: boolean
          default: false
          nullable: true
        top_logprobs:
          description: An integer between 0 and 5 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.
          type: integer
          minimum: 0
          maximum: 5
          nullable: true
        max_tokens:
          description: |
            The maximum number of [tokens](/tokenizer) that can be generated in the chat completion.

            The total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
          type: integer
          nullable: true
        n:
          type: integer
          minimum: 1
          maximum: 128
          default: 1
          example: 1
          nullable: true
          description: How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.
        presence_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
        response_format:
          type: object
          description: |
            An object specifying the format that the model must output. Compatible with [GPT-4 Turbo](/docs/models/gpt-4-and-gpt-4-turbo) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

            **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
          properties:
            type:
              type: string
              enum: ["text", "json_object"]
              example: "json_object"
              default: "text"
              description: Must be one of `text` or `json_object`.
        seed:
          type: integer
          minimum: -9223372036854775808
          maximum: 9223372036854775807
          nullable: true
          description: |
            This feature is in Beta.
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

        stop:
          description: |
            Up to 4 sequences where the API will stop generating further tokens.
          oneOf:
            - type: string
              nullable: true
            - type: array
              minItems: 1
              maxItems: 4
              items:
                type: string
        stream:
          description: >
            If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
          type: boolean
          nullable: true
          default: false
        temperature:
          type: number
          minimum: 0
          maximum: 2
          default: 1
          example: 1
          nullable: true
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          example: 1
          nullable: true
        tools:
          type: array
          description: >
            A list of tools the model may call. Currently, only functions are supported as a tool.
            Use this to provide a list of functions the model may generate JSON inputs for.
          items:
            $ref: "#/components/schemas/ChatCompletionTool"
        tool_choice:
          $ref: "#/components/schemas/ChatCompletionToolChoiceOption"
        user:
          type: string
          example: user-1234
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
        function_call:
          deprecated: true
          description: |
            Deprecated in favor of `tool_choice`.

            Controls which (if any) function is called by the model.
            `none` means the model will not call a function and instead generates a message.
            `auto` means the model can pick between generating a message or calling a function.
            Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

            `none` is the default when no functions are present. `auto` is the default if functions are present.
          oneOf:
            - type: string
              description: >
                `none` means the model will not call a function and instead generates a message.
                `auto` means the model can pick between generating a message or calling a function.
              enum: [none, auto]
            - $ref: "#/components/schemas/ChatCompletionFunctionCallOption"
          x-oaiExpandable: true
        functions:
          deprecated: true
          description: |
            Deprecated in favor of `tools`.

            A list of functions the model may generate JSON inputs for.
          type: array
          minItems: 1
          maxItems: 128
          items:
            $ref: "#/components/schemas/ChatCompletionFunctions"

      required:
        - model
        - messages

    CreateChatCompletionResponse:
      type: object
      description: Represents a chat completion response returned by model, based on the provided input.
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion.
        choices:
          type: array
          description: A list of chat completion choices. Can be more than one if `n` is greater than 1.
          items:
            type: object
            required:
              - finish_reason
              - index
              - message
              - logprobs
            properties:
              finish_reason:
                type: string
                description: &chat_completion_finish_reason_description |
                  The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
                  `length` if the maximum number of tokens specified in the request was reached,
                  `content_filter` if content was omitted due to a flag from our content filters,
                  `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
                enum:
                  [
                    "stop",
                    "length",
                    "tool_calls",
                    "content_filter",
                    "function_call",
                  ]
              index:
                type: integer
                description: The index of the choice in the list of choices.
              message:
                $ref: "#/components/schemas/ChatCompletionResponseMessage"
              logprobs: &chat_completion_response_logprobs
                description: Log probability information for the choice.
                type: object
                nullable: true
                properties:
                  content:
                    description: A list of message content tokens with log probability information.
                    type: array
                    items:
                      $ref: "#/components/schemas/ChatCompletionTokenLogprob"
                    nullable: true
                required:
                  - content
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created.
        model:
          type: string
          description: The model used for the chat completion.
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
        object:
          type: string
          description: The object type, which is always `chat.completion`.
          enum: [chat.completion]
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
        - choices
        - created
        - id
        - model
        - object

    ChatCompletionTokenLogprob:
      type: object
      properties:
        token: 
          description: The token.
          type: string
        logprob: 
          description: The log probability of this token.
          type: number
        bytes: 
          description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
          type: array
          items:
            type: integer
          nullable: true
        top_logprobs:
          description: List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.
          type: array
          items:
            type: object
            properties:
              token: 
                description: The token.
                type: string
              logprob: 
                description: The log probability of this token.
                type: number
              bytes: 
                description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
                type: array
                items:
                  type: integer
                nullable: true
            required:
              - token
              - logprob
              - bytes
      required:
        - token
        - logprob
        - bytes
        - top_logprobs

    CompletionUsage:
      type: object
      description: Usage statistics for the completion request.
      properties:
        completion_tokens:
          type: integer
          description: Number of tokens in the generated completion.
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt.
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion).
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens

security:
  - ApiKeyAuth: []